# Example configuration for federated learning experiments

# Experiment identification
experiment_name: "complete_fl_experiment"
experiment_type: "federated"  # Options: "local", "federated", "suppression", "differential_privacy"

# Data parameters
data_path: "datasets/dataset.parquet"
# p1_path: "datasets/p1.parquet"  # Uncomment if using pre-split datasets
# p2_path: "datasets/p2.parquet"  # Uncomment if using pre-split datasets
feature_columns:
  - 'protocol'
  - 'bidirectional_min_ps'
  - 'bidirectional_mean_ps'
  - 'bidirectional_stddev_ps'
  - 'bidirectional_max_ps'
  - 'src2dst_stddev_ps'
  - 'src2dst_max_ps'
  - 'dst2src_min_ps'
  - 'dst2src_mean_ps'
  - 'dst2src_stddev_ps'
  - 'dst2src_max_ps'
  - 'bidirectional_stddev_piat_ms'
  - 'bidirectional_max_piat_ms'
  - 'bidirectional_rst_packets'
target_column: 'application_name'

# Dataset splitting parameters
seed: 42
initial_split_ratio: 0.5  # First split into P1/P2
test_split_ratio: 0.1667  # Test split ratio for each participant

# Training parameters
batch_size: 256
learning_rate: 0.001

# Local training parameters (for local experiment)
local_epochs: 100

# Federated learning parameters
federated_rounds: 10
client_epochs: 10  # Epochs per federated round

# Privacy parameters
# For suppression - uncomment and edit for suppression experiments
# p1_features:  # Features for Player 1 (leave empty for all features)
#   - 'protocol'
#   - 'bidirectional_min_ps'
#   - 'bidirectional_mean_ps'
# p2_features:  # Features for Player 2 (leave empty for all features)
#   - 'protocol'
#   - 'bidirectional_min_ps'
#   - 'bidirectional_mean_ps'
#   - 'bidirectional_stddev_ps'

# For differential privacy - uncomment and edit for DP experiments
# noise_multiplier_p1: 0.5  # Noise for Player 1 (None for no noise)
# noise_multiplier_p2: 1.0  # Noise for Player 2 (None for no noise)
max_grad_norm: 1.0  # Maximum gradient norm for DP
max_epsilon: 10.0  # Maximum allowed privacy budget
max_parallel_dp_processes: 2  # Limit parallel DP processes to avoid memory issues

# Result paths
results_dir: "results"
logs_dir: "logs"
save_models: false
checkpoint_interval: 1  # Save results every N rounds/epochs